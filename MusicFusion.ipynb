{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 19:24:32 WARN Utils: Your hostname, Ronits-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.3 instead (on interface en0)\n",
      "24/06/13 19:24:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/13 19:24:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/13 19:24:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "%run Requirements.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    user='root',\n",
    "    password='ronitgupta28',\n",
    "    database='MusicFusion'\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Music Artist Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT SM.Artists\n",
    "    FROM PARQUET.`/Users/ronitguptaaa/Documents/Music-Fusion-APP/Staging/AppleMusic` AS AM\n",
    "    INNER JOIN PARQUET.`/Users/ronitguptaaa/Documents/Music-Fusion-APP/Staging/SpotifyMusic` AS SM \n",
    "    ON LTRIM(RTRIM(LOWER(AM.`Artist Name`))) = LTRIM(RTRIM(LOWER(SM.Artists)))\n",
    "    LEFT JOIN PARQUET.`/Users/ronitguptaaa/Documents/Music-Fusion-APP/Staging/YoutubeMusic` AS YM\n",
    "    ON LTRIM(RTRIM(LOWER(AM.`Artist Name`))) = LTRIM(RTRIM(LOWER(YM.`Artist Name`)))\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/10 15:50:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "artists_df = df.select(F.col('Artists')).distinct()\n",
    "artists_list = [row['Artists'] for row in artists_df.collect()]\n",
    "\n",
    "news_api_key = News_API.get('API_KEY')\n",
    "\n",
    "news_data = []\n",
    "for artist in artists_list:\n",
    "    url = f\"https://newsapi.org/v2/everything?q={artist}&pageSize=10&apiKey={news_api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json()['articles']\n",
    "        for article in articles:\n",
    "            news_data.append({\n",
    "                'Artist': artist,\n",
    "                'Title': article.get('title'),\n",
    "                'Description': article.get('description'),\n",
    "                'URL': article.get('url'),\n",
    "                'Content': article.get('content')\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Failed to fetch news for artist: {artist}, Status Code: {response.status_code}\")\n",
    "\n",
    "news_df = pd.DataFrame(news_data)\n",
    "news_spark_df = spark.createDataFrame(news_df)\n",
    "\n",
    "news_spark_df.write.mode('overwrite').format('parquet').save('Mart/MusicFusion-Details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/ronitguptaaa/Documents/Music-Fusion-APP/Mart/MusicFusion-Details')\n",
    "\n",
    "columns = \", \".join([f\"`{col}` VARCHAR(1024)\" for col in df.columns])\n",
    "drop_table_query = f\"DROP TABLE IF EXISTS MusicFusionDetails;\"\n",
    "cursor.execute(drop_table_query)\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS MusicFusionDetails ({columns});\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    values = tuple(row.values)\n",
    "    insert_query = f\"REPLACE INTO MusicFusionDetails VALUES {values};\"\n",
    "    cursor.execute(insert_query)\n",
    "    \n",
    "alter_table_query = f\"DELETE FROM MusicFusionDetails WHERE Title = '[Removed]'\"\n",
    "cursor.execute(alter_table_query)\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple Music Artist Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/05 10:34:11 WARN ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT DISTINCT * FROM PARQUET.`/Users/ronitguptaaa/Documents/Music-Fusion-APP/Staging/AppleMusic`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/05 10:35:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/06/05 10:35:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "artists_df = df.select(F.col('Artist Name')).distinct()\n",
    "artists_list = [row['Artist Name'] for row in artists_df.collect()]\n",
    "\n",
    "news_api_key = News_API.get('API_KEY')\n",
    "\n",
    "news_data = []\n",
    "for artist in artists_list:\n",
    "    url = f\"https://newsapi.org/v2/everything?q={artist}&pageSize=10&apiKey={news_api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json()['articles']\n",
    "        for article in articles:\n",
    "            news_data.append({\n",
    "                'Artist': artist,\n",
    "                'Title': article.get('title'),\n",
    "                'Description': article.get('description'),\n",
    "                'URL': article.get('url'),\n",
    "                'Content': article.get('content')\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Failed to fetch news for artist: {artist}, Status Code: {response.status_code}\")\n",
    "\n",
    "news_df = pd.DataFrame(news_data)\n",
    "news_spark_df = spark.createDataFrame(news_df)\n",
    "\n",
    "news_spark_df.write.mode('overwrite').format('parquet').save('Mart/AppleMusic-Details')\n",
    "news_spark_df.write.mode('overwrite').format('parquet').saveAsTable('AppleMusicDetails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/ronitguptaaa/Documents/Music-Fusion-APP/Mart/AppleMusic-Details')\n",
    "\n",
    "columns = \", \".join([f\"`{col}` VARCHAR(1024)\" for col in df.columns])\n",
    "drop_table_query = f\"DROP TABLE IF EXISTS AppleMusicDetails;\"\n",
    "cursor.execute(drop_table_query)\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS AppleMusicDetails ({columns});\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    values = tuple(row.values)\n",
    "    insert_query = f\"REPLACE INTO AppleMusicDetails VALUES {values};\"\n",
    "    cursor.execute(insert_query)\n",
    "\n",
    "alter_table_query = f\"DELETE FROM AppleMusicDetails WHERE Title = '[Removed]'\"\n",
    "cursor.execute(alter_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify Artist Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/05 10:38:04 WARN ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT DISTINCT * FROM PARQUET.`/Users/ronitguptaaa/Documents/Music-Fusion-APP/Staging/SpotifyMusic`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/05 10:40:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/06/05 10:40:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "artists_df = df.select(F.col('Artists')).distinct()\n",
    "artists_list = [row['Artists'] for row in artists_df.collect()]\n",
    "\n",
    "news_api_key = News_API.get('API_KEY')\n",
    "\n",
    "news_data = []\n",
    "for artist in artists_list:\n",
    "    url = f\"https://newsapi.org/v2/everything?q={artist}&pageSize=10&apiKey={news_api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json()['articles']\n",
    "        for article in articles:\n",
    "            news_data.append({\n",
    "                'Artist': artist,\n",
    "                'Title': article.get('title'),\n",
    "                'Description': article.get('description'),\n",
    "                'URL': article.get('url'),\n",
    "                'Content': article.get('content')\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Failed to fetch news for artist: {artist}, Status Code: {response.status_code}\")\n",
    "\n",
    "news_df = pd.DataFrame(news_data)\n",
    "news_spark_df = spark.createDataFrame(news_df)\n",
    "\n",
    "news_spark_df.write.mode('overwrite').format('parquet').save('Mart/Spotify-Details')\n",
    "news_spark_df.write.mode('overwrite').format('parquet').saveAsTable('SpotifyDetails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/ronitguptaaa/Documents/Music-Fusion-APP/Mart/Spotify-Details')\n",
    "\n",
    "columns = \", \".join([f\"`{col}` VARCHAR(1024)\" for col in df.columns])\n",
    "drop_table_query = f\"DROP TABLE IF EXISTS SpotifyDetails;\"\n",
    "cursor.execute(drop_table_query)\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS SpotifyDetails ({columns});\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    values = tuple(row.values)\n",
    "    insert_query = f\"REPLACE INTO SpotifyDetails VALUES {values};\"\n",
    "    cursor.execute(insert_query)\n",
    "\n",
    "alter_table_query = f\"DELETE FROM SpotifyDetails WHERE Title = '[Removed]'\"\n",
    "cursor.execute(alter_table_query)\n",
    "\n",
    "conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
